{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLUi6Len6l_8"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAgJ_IMz6mAD"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2ydiZWZ6mAF"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5sqmoq76mAG",
        "outputId": "756b63c7-d746-46a3-dd10-c507e40fcd0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\"\"\"\n",
        "#TODO: Resample the dataset if needed\n",
        "X_train = ...\n",
        "y_train = ...\n",
        "X_test = ...\n",
        "y_test = ...\n",
        "\"\"\"\n",
        "\n",
        "X_train.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVPhAL-6mAM"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser *italicized text*\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjTqDdKP6mAN"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "rCzBZKfR6mAO",
        "outputId": "bf8eb235-7dfa-4f58-9b1f-302153fff95a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtDg-5iM6mAQ"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7zuIrUc6mAR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9U1G9PU6mAS"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWZRsug46mAT",
        "outputId": "87cdd4b5-7dc7-4994-95ba-8513aeac82f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network|\n",
        "print(np.shape(X_train_norm))\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_train_norm))\n",
        "\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy65UNwL6mAT"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "26KvmNkZ6mAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c77bb8-e5c7-473b-97d7-c885b1f5ef61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8070 (31.52 KB)\n",
            "Trainable params: 8070 (31.52 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='sigmoid'))\n",
        "    model.add(Dense(10, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "    return model\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2mbvZEK6mAW"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "id": "fRLAM06S6mAW",
        "outputId": "d8d5685a-f787-4b55-9dfc-4bd49188007c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 1.8952 - accuracy: 0.3674\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.3981 - accuracy: 0.5579\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.1249 - accuracy: 0.6555\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.9363 - accuracy: 0.7279\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7705 - accuracy: 0.7748\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.6613 - accuracy: 0.7894\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5987 - accuracy: 0.7981\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5609 - accuracy: 0.8034\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.5352 - accuracy: 0.8087\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.8131\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5017 - accuracy: 0.8178\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.8217\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4789 - accuracy: 0.8271\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4697 - accuracy: 0.8324\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.8372\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4512 - accuracy: 0.8432\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4439 - accuracy: 0.8454\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8493\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.8526\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4217 - accuracy: 0.8546\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4162 - accuracy: 0.8571\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4107 - accuracy: 0.8585\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4061 - accuracy: 0.8592\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4010 - accuracy: 0.8620\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3969 - accuracy: 0.8625\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3932 - accuracy: 0.8638\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3884 - accuracy: 0.8652\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3859 - accuracy: 0.8663\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3822 - accuracy: 0.8663\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8684\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8696\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3728 - accuracy: 0.8699\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3682 - accuracy: 0.8717\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3667 - accuracy: 0.8717\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3634 - accuracy: 0.8723\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8724\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3593 - accuracy: 0.8736\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3581 - accuracy: 0.8733\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3542 - accuracy: 0.8754\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8755\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3516 - accuracy: 0.8756\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3523 - accuracy: 0.8752\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8773\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3470 - accuracy: 0.8768\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8775\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8778\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8788\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3402 - accuracy: 0.8788\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8798\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3376 - accuracy: 0.8803\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3364 - accuracy: 0.8802\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8813\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8812\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3334 - accuracy: 0.8816\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3318 - accuracy: 0.8827\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8829\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3306 - accuracy: 0.8832\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8827\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3281 - accuracy: 0.8833\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8842\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3261 - accuracy: 0.8844\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8844\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8849\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3234 - accuracy: 0.8856\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.8846\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3208 - accuracy: 0.8865\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3206 - accuracy: 0.8862\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3197 - accuracy: 0.8866\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3194 - accuracy: 0.8861\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3182 - accuracy: 0.8870\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3174 - accuracy: 0.8875\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3168 - accuracy: 0.8869\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3174 - accuracy: 0.8877\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3166 - accuracy: 0.8875\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3150 - accuracy: 0.8887\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8885\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3129 - accuracy: 0.8887\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8882\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3121 - accuracy: 0.8889\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8889\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8889\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3112 - accuracy: 0.8893\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3100 - accuracy: 0.8899\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3101 - accuracy: 0.8899\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.8907\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.8906\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8906\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3065 - accuracy: 0.8907\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8905\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3052 - accuracy: 0.8917\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3063 - accuracy: 0.8917\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3041 - accuracy: 0.8917\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8905\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3046 - accuracy: 0.8906\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3028 - accuracy: 0.8923\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8921\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3026 - accuracy: 0.8923\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3022 - accuracy: 0.8923\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3011 - accuracy: 0.8928\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3012 - accuracy: 0.8931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a8896303f40>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0Ch8p6A6mAY"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeJdKwrR6mAY",
        "outputId": "8c9f3916-275e-49e3-ff1d-3c4971982387"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-15 10:36:04.803861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy on train with NN: 0.9000000357627869\n",
            "accuracy on test with NN: 0.8375000357627869\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PYpePvr6mAZ"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vSMLHZF6mAa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOurFjQb6mAa"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U4sSTdHl6mAa"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "esi3x3ln6mAb",
        "outputId": "43cd774d-45fd-47a0-ca54-89be1e00cc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.8632\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on test', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36E3U8pX6mAc"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yciPaZFK6mAc"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}